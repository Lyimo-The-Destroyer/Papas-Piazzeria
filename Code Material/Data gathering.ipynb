{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webscraping neighbourhood income data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Neighbourhood  Median Income Before Tax\n",
      "0                         Toronto                     97000\n",
      "1                 Agincourt North                     89000\n",
      "2    Agincourt South-Malvern West                     89000\n",
      "3                    Malvern East                     89000\n",
      "4                    Malvern West                     89000\n",
      "..                            ...                       ...\n",
      "141             Greenwood-Coxwell                     95000\n",
      "142              Woodbine-Lumsden                     96000\n",
      "143                      Wychwood                     86000\n",
      "144                Yonge-Eglinton                     94000\n",
      "145               Yonge-St. Clair                     94000\n",
      "\n",
      "[146 rows x 2 columns]\n",
      "Data has been written to median_income_by_neighbourhood.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the webpage\n",
    "url = \"https://www03.cmhc-schl.gc.ca/hmip-pimh/en/TableMapChart/TableMatchingCriteria?GeographyType=MetropolitanMajorArea&GeographyId=2270&CategoryLevel1=Population%2C%20Households%20and%20Housing%20Stock&CategoryLevel2=Household%20Income&ColumnField=HouseholdIncomeRange&RowField=Neighbourhood&SearchTags%5B0%5D.Key=Households&SearchTags%5B0%5D.Value=Number&SearchTags%5B1%5D.Key=Statistics&SearchTags%5B1%5D.Value=AverageAndMedian\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find the table containing the neighborhood and median income data\n",
    "table = soup.find('table', class_='CawdDataTable')\n",
    "\n",
    "# List of neighborhoods to exclude\n",
    "excluded_neighborhoods = {\n",
    "    'Ajax', 'Aurora', 'Bradford', 'Brampton (East)', 'Brampton (West)', \n",
    "    'Caledon', 'East Gwillimbury', 'Georgina', 'Halton Hills', 'Milton', \n",
    "    'Mississauga Centre', 'Mono', 'New Tecumseth', 'Newmarket', \n",
    "    'Oakville (excl. Bronte)', 'Orangeville', 'Pickering', \n",
    "    'Richmond Hill', 'Stouffville', 'Uxbridge', 'Vaughan', 'Whitchurch', \"Bronte\",\n",
    "    \"Churchill Meadows\", \"City Centre North\", \"City Centre South\", \"Clarkson\",\n",
    "    \"Cooksville\", \"Crescent Town\", \"Davenport\", \"Erin Mills\",\n",
    "    \"King\", \"King West\", \"Lorne Park\", \"Malton\", \"Markham\", \"Meadowvale\",\n",
    "    \"Moore Park\", \"Port Credit\", \"Streetsville\", \"West Gwillimbury\"\n",
    "}\n",
    "\n",
    "# List of neighbourhood replacements\n",
    "replacements = {\n",
    "    \"Bendale\": [\"Bendale South\", \"Bendale-Glen Andrew\"],\n",
    "    \"Agincourt\": [\"Agincourt North\", \"Agincourt South-Malvern West\"],\n",
    "    \"Willowdale East\": [\"Avondale\", \"Willowdale East\", \"Yonge-Doris\"],\n",
    "    \"Bay Street Corridor\": [\"Bay-Cloverhill\", \"Yonge-Bay Corridor\"],\n",
    "    \"Church-Yonge Corridor\": [\"Church-Wellesley\", \"Downtown Yonge East\"],\n",
    "    \"Dovercourt\": [\"Dovercourt Village\", \"Junction-Wallace Emerson\"],\n",
    "    \"Downsview\": [\"Downsview\", \"Oakdale-Beverly Heights\"],\n",
    "    \"Parkwoods-Donalda\": [\"Fenside-Parkwoods\", \"Parkwoods-O'Connor Hills\"],\n",
    "    \"Woburn\": [\"Golfdale-Cedarbrae-Woburn\", \"Woburn North\"],\n",
    "    \"Waterfront Communities -The Island\": [\"Harbourfront-CityPlace\", \"St Lawrence-East Bayfront The Islands\", \"Wellington Place\"],\n",
    "    \"Mimico\": [\"Humber Bay Shores\", \"Mimico-Queensway\"],\n",
    "    \"L'Amoreaux\": [\"East L'Amoreaux\", \"West L'Amoreaux\"],\n",
    "    \"Malvern\": [\"Malvern East\", \"Malvern West\"],\n",
    "    \"Rouge\": [\"Morningside\", \"Rouge\"],\n",
    "    \"Morningside\": [\"Morningside Heights\"],\n",
    "    \"Riverdale\": [\"North Riverdale\", \"South Riverdale\"],\n",
    "    \"Mount Pleasant West\": [\"North Toronto\",\"South Eglinton-Davisville\"],\n",
    "    \"Weston\": [\"Weston\", \"Weston-Pelham Park\"]\n",
    "}\n",
    "\n",
    "# Initialize lists to store neighborhood names and median incomes\n",
    "neighborhoods = []\n",
    "median_incomes = []\n",
    "\n",
    "# Loop through each row of the table, except the header and footer\n",
    "for row in table.find_all('tr')[1:-1]:  # skip header and footer rows\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells) > 1:\n",
    "        neighborhood = row.find('th').get_text(strip=True)\n",
    "        median_income = cells[3].get_text(strip=True).replace(',', '').replace('$', '')  # Clean up the income value\n",
    "        median_income = int(median_income)  # Convert to integer\n",
    "\n",
    "        # Split neighborhoods with a slash and duplicate the median income\n",
    "        for nb in neighborhood.split('/'):\n",
    "            nb = nb.strip()  # Remove leading and trailing whitespace\n",
    "            if nb in replacements:  # Check if the neighborhood has replacements\n",
    "                for new_nb in replacements[nb]:\n",
    "                    if new_nb not in excluded_neighborhoods:  # Check if new neighborhood is excluded\n",
    "                        neighborhoods.append(new_nb)  # Add the new neighborhood\n",
    "                        median_incomes.append(median_income)  # Add the same median income\n",
    "            elif nb not in excluded_neighborhoods:  # If no replacements and not excluded\n",
    "                neighborhoods.append(nb)  # Add the split neighborhood\n",
    "                median_incomes.append(median_income)  # Add the same median income\n",
    "\n",
    "# Create a DataFrame from the lists\n",
    "income_df = pd.DataFrame({\n",
    "    'Neighbourhood': neighborhoods,\n",
    "    'Median Income Before Tax': median_incomes\n",
    "})\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "csv_file_path = 'median_income_by_neighbourhood.csv'\n",
    "income_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(income_df)\n",
    "print(f'Data has been written to {csv_file_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the water levels at black creek and don river for flooding event of interest (july 8th 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID       Date   Value\n",
      "25207  02HC027 2013-07-08   1.426\n",
      "55249  02HC024 2013-07-08  13.026\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data file\n",
    "file_name = 'flow data.csv'\n",
    "data = pd.read_csv(file_name, header=None, skiprows=1)\n",
    "\n",
    "# Assign column names\n",
    "data.columns = ['ID', 'PARAM', 'Date', 'Value', 'SYM']\n",
    "\n",
    "# Convert 'Date' to datetime format and filter 'PARAM' column for valid values\n",
    "data['Date'] = pd.to_datetime(data['Date'], errors='coerce')\n",
    "data = data[data['PARAM'].isin(['1', '2'])].copy()\n",
    "data['PARAM'] = data['PARAM'].astype(int)\n",
    "\n",
    "# Filter for July 8, 2013, and parameter 2 (level data)\n",
    "july_8_2013_level_data = data[(data['PARAM'] == 2) & (data['Date'] == '2013-07-08')]\n",
    "\n",
    "july_8_2013_level_data = july_8_2013_level_data [['ID','Date','Value']]\n",
    "\n",
    "# Display the filtered data\n",
    "print(july_8_2013_level_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the baseline water levels for these rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "july basline water level         ID  Baseline_July_Water_Level\n",
      "0  02HC024                  12.195959\n",
      "1  02HC027                   0.381672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayac\\AppData\\Local\\Temp\\ipykernel_14700\\2444658108.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  water_level_data['Value'] = pd.to_numeric(water_level_data['Value'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Filter only for PARAM = 2 (water level data) and convert 'Value' to numeric\n",
    "water_level_data = data[data['PARAM'] == 2]\n",
    "water_level_data['Value'] = pd.to_numeric(water_level_data['Value'], errors='coerce')\n",
    "\n",
    "# Filter data for July across all years\n",
    "july_water_level_data = water_level_data[water_level_data['Date'].dt.month == 7]\n",
    "\n",
    "# Calculate the average (baseline) water level for each gauge for July\n",
    "baseline_july_water_levels = july_water_level_data.groupby('ID')['Value'].mean().reset_index()\n",
    "baseline_july_water_levels.columns = ['ID', 'Baseline_July_Water_Level']\n",
    "\n",
    "# Display the result\n",
    "print(baseline_july_water_levels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      x          y  STATION_NAME LOCAL_DATE  TOTAL_PRECIPITATION\n",
      "6 -79.4  43.666667  TORONTO CITY 2013-07-07                 38.5\n",
      "7 -79.4  43.666667  TORONTO CITY 2013-07-08                 96.8\n"
     ]
    }
   ],
   "source": [
    "# Load the data file\n",
    "climate_file = 'climate-daily.csv'\n",
    "climate_data = pd.read_csv(climate_file)\n",
    "\n",
    "# Convert 'LOCAL_DATE' to datetime format\n",
    "climate_data['LOCAL_DATE'] = pd.to_datetime(climate_data['LOCAL_DATE'], errors='coerce')\n",
    "\n",
    "# Filter for data from July 7th and 8th, 2013\n",
    "july_7_8_data = climate_data[(climate_data['LOCAL_DATE'] == '2013-07-07') | (climate_data['LOCAL_DATE'] == '2013-07-08')]\n",
    "\n",
    "# Select only the columns of interest: 'x', 'y', 'STATION_NAME', 'LOCAL_DATE', and 'TOTAL_PRECIPITATION'\n",
    "july_7_8_selected_columns = july_7_8_data[['x', 'y', 'STATION_NAME', 'LOCAL_DATE', 'TOTAL_PRECIPITATION']]\n",
    "\n",
    "# Display the filtered data\n",
    "print(july_7_8_selected_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
